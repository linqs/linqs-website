{
    "type": "conference",
    "title": "Efficient Learning Losses for Deep Hinge-Loss Markov Random Fields",
    "authors": [
        "Charles Dickens",
        "Connor Pryor",
        "Eriq Augustine",
        "Alon Albalak",
        "Lise Getoor"
    ],
    "venue": "Workshop on Tractable Probabilistic Modeling",
    "year": "2022",
    "publisher": "TPM",
    "address": "Eindhoven, Netherlands",
    "abstract" : "In this work, we examine the learning process for Neural Probabilistic Soft Logic (NeuPSL) [Pryor et al., 2022]. NeuPSL is a novel neuro-symbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks to create a tractable probabilistic model that supports end-to-end learning via back-propagation. We investigate two common learning losses, Energy-based and Structured Perceptron. We provide formal definitions, and identify and propose principled fixes to degenerate solutions. We then perform an extensive evaluation over a canonical NeSy task.",
    "keywords": [
        "psl"
    ]
}
